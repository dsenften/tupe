## Chapter 3: Using the Shell

The shell - the program that interprets your request to run programs - is the most important program for UNIX users; with the possible exception of your favorite text editor, you will spend more time working with the shell than any other program.
In this chapter and in Chapter 5, we will spend a fair amount of time on the shell's capabilities.
The main point we want to make is that you can accomplish a lot without much hard work, and certainly without resorting to programming in a conventional language, like C, if you know how to use the shell.

We have divided our coverage of the shell into two chapters.
This chapter goes one step beyond the necessities covered in Chapter 1 to some fancier but commonly used shell features, such as metacharacters, quoting, creating new commands, passing arguments to them, the use of shell variables, and some elementary
flow control.
These are topics you should know for your own use of the shell.
The material in Chapter 5 is heavier going - and is intended for writing serious shell programs, ones that are bullet-proofed for use by others.
The division between the two chapters is somewhat arbitrary, of course, so both should be read eventually.

### 3.1 Command line structure

To proceed, we need a slightly better understanding of just what a command is, and how it is interpreted by the shell.
This section is a more formal coverage, with some new information, of the shell basics introduced in the first chapter.

The simplest command is a single *word*, usually naming a file for execution (later we will see some other types of commands):
```
$ who
you        tty2    Sep 28 07:51
jpl        tty4    Sep 28 08:32
$
```
A command usually ends with a newline, but a semicolon `;` is also a *command terminator*:
```
$ date;
Wed Sep 28 09:07:15 EDT 1983
$ date; who
Wed Sep 28 09:07:23 EDT 1983
you        tty2    Sep 28 07:51
jpl        tty4    Sep 28 08:32
$
```
Although semicolons can be used to terminate commands, as usual nothing happens until you type RETURN.
Notice that the shell only prints one prompt after multiple commands, but except for the prompt,
```
$ date; who
```
is identical to typing the two commands on different lines.
In particular, `who` doesn't run until `date` is finished.

Try sending the output of `date; who` through a pipe:
```
$ date; who | wc
Wed Sep 28 09:08:48 EDT 1983
      2     10     60
$
```
This might not be what you expected, because only the output of `who` goes to `wc`.
Connecting `who` and `wc` with a pipe forms a single command called a *pipeline*, that runs after `date`.
The precedence of `|` is higher than that of `;` as the shell parses your command line.

Parentheses can be used to group commands:
```
$ (date; who)
Wed Sep 28 09:11:09 EDT 1983
you        tty2    Sep 28 07:51
jpl        tty4    Sep 28 08:32
$ (date; who) | wc
      3      16     89
$
```
The outputs of `date` and `who` are concatenated into a single stream that can be sent down a pipe.

Data glowing through a pipe can be tapped and placed in a file (but not another pipe) with the `tee` command, which is not part of the shell, but is nonetheless handy for manipulating pipes.
One use is to save intermediate output in a file:
```
$ (date; who) | tee save | wc
      3      16     89
$ cat save
Wed Sep 28 09:13:22 EDT 1983
you        tty2    Sep 28 07:51
jpl        tty4    Sep 28 08:32
$ wc < save
      3      16     89
$
```
`tee` copies its input to the named file or files, as well as to its output, so `wc` receives the same data as if `tee` weren't in the pipeline.

Another command terminator is the ampersand `&`.
It's exactly like the semicolon or newline, except that it tells the shell not to wait for the command to complete.
Typically, `&` is used to run a long-running command "in the background" while you continue to type interactive commands:
```
$ long-running-command &
5273                             Process-id of long-running-command
$                                Prompt appears immediately
```
Given the ability to group commands, there are some more interesting uses of background processes.
The command `sleep` waits the specified number of seconds before exiting:
```
$ sleep 5
$                                Five seconds pass before prompt
$ (sleep 5; date) & date
5278
Wed Sep 28 09:18:20 EDT 1983     Output from second date
$ Wed Sep 28 09:18:25 EDT 1983   Prompt appears, then date 5 seconds later
```
The background process starts but immediately sleeps; meanwhile, the second `date` command prints the current time and the shell prompts for a new command.
Five seconds later, the `sleep` exits and the first `date` prints the new time.
It's hard to represent the passage of time on paper, so you should try this example.
(Depending on how busy your machine is and other such details, the difference between the two times might not be exactly five seconds.)
This is an easy way to run a command in the future; consider
```
$ (sleep 300; echo "Tea is ready") &
5291
$
```
as a handy reminder mechanism.
(A `ctl-g` in the string to be `echo`ed will ring the terminal's bell when it's printed.)
The parentheses are needed in these examples, since the precedence of `&` is higher than that of `;`.

The `&` terminator applies to commands, and since pipelines are commands you don't need parentheses to run pipelines in the background:
```
$ pr file | lpr &
```
arranges to print the file on the line printer without making you wait for the command to finish.
Parenthesizing the pipeline has the same effect, but requires more typing:
```
$ (pr file | lpr) &              Same as last example
```

Most programs accept *arguments* on the command line, such as `file` (an argument to `pr`) in the above example.
Arguments are words separated by blanks and tabs, that typically name files to be processed by the command, but they are strings that may be interpreted any way the program sees fit.
For example, `pr` accepts names of files to print, `echo` echoes it's arguments without interpretation, and `grep`'s first argument specifies a text pattern to search for.
And, of course, most programs also have options, indicated by arguments beginning with a minus sign.

The various special characters interpreted by the shell, such as `<`, `>`, `|`, `;`, and `&`, are *not* arguments for the programs the shell runs.
They instead control how the shell runs them.
For example,
```
$ echo Hello > junk
```
tells the shell to run `echo` with the single argument `Hello`, and place the output in the file called `junk`.
The string `> junk` is not an argument to `echo`; it is interpreted by the shell and never seen by `echo`.
In fact, it need not be the last string in the command:
```
> junk echo Hello
```
is identical, but less obvious.

### 3.2 Metacharacters

The shell recognizes a number of other characters as special; the most commonly used is the asterisk `*` which tells the shell to search the directory for filenames in which any string of characters occurs in the position of the `*`.
For example,
```
$ echo *
```
is a poor facsimile of `ls`.
Something we didn't mention in Chapter 1 is that the filename-matching characters do not look at filenames beginning with a dot, to avoid problems with the names `.` and `..` that are in every directory.
The rule is: the filename-matching characters only match filenames beginning with a period if the period is explicitly supplied in the pattern.
As usual, a judicious `echo` or two will clarify what happens:
```
$ ls
.profile
junk
temp
$ echo *
junk temp
$ echo .*
. .. .profile
$
```

Characters like `*` that have special properties are known as *metacharacters*.
There are a lot of them: Table 3.1 is the complete list, although a few of them won't be discussed until Chapter 5.

| Character          | Description                                                                          |
|--------------------|--------------------------------------------------------------------------------------|
| `>`                | `prog > file` direct standard output to `file`                                       |
| `>>`               | `prog >> file` append standard output to `file`                                      |
| `<`                | `prog < file` take standard input from `file`                                        |
| `pipe`             | `p1 pipe p2` connect standard output of `p1` to standard input of `p2`               |
| `<<str`            | *here document*: standard input follows, up to next `str` on a line by itself        |
| `*`                | match any string of zero or more characters in filenames                             |
| `?`                | match any single character in filenames                                              |
| `[ccc]`            | match any single character from `ccc` in filenames; <br/> ranges like `0-9` or `a-z` |
| `;`                | command terminator: `p1;p2` does `p1`, then `p2`                                     |
| `&`                | like `;` but doesn't wait for `p1` to finish                                         |
| \`...\`            | run command(s) in `...`; output replaces \`...\`                                     |
| `(...)`            | run command(s) in `...` in a sub-shell                                               |
| `{...}`            | run command(s) in `...` in current shell (rarely used)                               |
| `$1`, `$2`, *etc.* | `$0`...`$9` replaced by arguments to shell file                                      |
| `$var`             | value of shell variable `var`                                                        |
| `${var}`           | value of `var`; avoids confusion when concatenated with text                         |
| `\\`               | `\c` take character `c` literally, `\newline` discarded                              |
| `'...'`            | take `...` literally                                                                 |
| `"..."`            | take `...` literally after `$`, `'...'`, and `\\` interpreted                        |
| `#`                | if `#` starts word, rest of line is a comment                                        |
| `var=value`        | assign to variable `var`                                                             |
| `p1 && p2`         | run `p1`; if successful, run `p2`                                                    |
| `p1 pipe pipe p2`  | run `p1`; if unsuccessful run `p2 `                                                  |

Given the number of shell metacharacters, there has to be some way to tell the shell, "Leave it alone."
The easiest and best way to protect special characters from being interpreted is to enclose them in single quote characters"
```
$ echo '***'
***
$
```
It's also possible to use the double quotes `"..."`, but the shell actually peeks inside these quotes to look for `$`, \`...\`, and `\\`, so don't use `"..."` unless you intend some processing of the quoted string.

A third possibility is to put a backslash `\\` in front of *each* character that you want to protect from the shell, as in 
```
$ echo \*\*\*
***
$
```
Although `\*\*\*` isn't much like English, the shell terminology for it is still a *word*, which is any single string the shell accepts as a unit, including blanks if they are quoted.

Quotes of one kind protect quotes of the other kind:
```
$ echo "Don't do that!"
Don't do that!
$
```
and they don't have to surround the whole argument:
```
$ echo x'*'y
x*y
$ echo '*'A'?'
*A?
$
```
In this last example, because the quotes are discarded after they've done their job, `echo` sees a single argument containing no quotes.

Quoted strings can contain newlines:
```
$ echo 'hello
> world'
hello
world
$
```
The string `'> '` is a *secondary prompt* printed by the shell when it expects you to type more input to complete a command.
In this example the quote on the first line has to be balanced with another.
The secondary prompt string is stored in the shell variable `PS2`, and can be modified to taste.

In all of these examples, the quoting of a metacharacter prevents the shell from trying to interpret it.
The command
```
$ echo x*y
```
echoes all the filenames beginning in `x` and ending in `y`.
As always, `echo` knows nothing about files or shell metacharacters; the interpretation of `*`, if any, is supplied by the shell.

What happens if no files match the pattern?
The shell, rather than complaining (as it did in early versions), passes the string on as though it had been quoted.
It's usually a bad idea to depend on this behavior, but it can be exploited to learn of the existence of files matching a pattern:
```
$ ls x*y
x*y not found          Message from ls: no such files exist
$ > xyzzy              Create xyzzy
$ ls x*y
xyzzy                  File xyzzy matches x*y
$ ls 'x*y'
x*y not found          ls doesn't interpret the *
$
```

A backslash at the end of a line causes the line to be continued; this is the way to present a very long line to the shell.
```
echo abc\
> def\
> ghi
abcdefghi
$
```
Notice that the newline is discarded when preceded by a backslash, but is retained when it appears in quotes.

The metacharacter `#` is almost always universally used for shell comments; if a shell word begins with `#`, the rest of the line is ignored:
```
$ echo hello # there
hello
$ echo hello#there
hello#there
$
```
The `#` was not part of the original 7th Edition, but it has been adopted very widely, and we will use it in the rest of the book.

#### A digression on `echo`

### 3.3 Creating new commands

It's now time to move on to something that we promised in Chapter 1 - how to create new commands out of old ones.

Given a sequence of commands that is to be repeated more than a few times, it would be convenient to make it into a "new" command with its own name, so you can use it like a regular command.
To be specific, suppose you intend to count users frequently with the pipeline
```
$ who | wc -l
```
that was mentioned in Chapter 1, and you want to make a new program `nu` (number users) to do that.

The first step is to create an ordinary file that contains `who | wc -l`.
You can use a favorite editor, or you can get creative:
```
$ echo 'who | wc -l' > nu
```
(Without the quotes what would appear in `nu`?)

As we said in Chapter 1, the shell is a program just like an editor or `who` or `wc`; its name is `sh`.
And since it's a program, you can run it and redirect *its* input.
So run the shell with its input coming from the `nu` file instead of the terminal:
```
$ who
you     tty2   Sep 28 07:51
rhh     tty4   Sep 28 10:02
moh     tty5   Sep 28 09:38
ava     tty6   Sep 28 10:17
$ cat nu
who | wc -l
$ sh < nu
      4
$
```
The output is the same as it would have been if you had typed `who | wc -l` at the terminal.

Again like most other programs, the shell takes its input from a file if one is named as an argument; you could have written
```
$ sh nu
```
for the same result.
But it's a nuisance to have to type `"sh"` in either case: its longer, and it creates a distinction between programs written in, say, C and ones written by connecting programs with the shell.
Therefore, if a file is executable and if it contains text, then the shell assumes it to be a file of shell commands.
Such a file is called a *shell file*.
All you have to do is to make `nu` executable, once:
```
$ chmod +x nu
```
and thereafter you can invoke it with
```
$ nu
```
From now on, users of `nu` cannot tell, just by running it, that you implemented it in this easy way.

The way a shell actually runs `nu` is to create a new shell process exactly as if you had typed
```
$ sh nu
```
This child shell is called a *sub-shell* - a shell process invoked by your current shell.
`sh nu` is not the same as `sh < nu`, because its standard input is still connected to the terminal.

As it stands, `nu` only works if it's in your current directory (provided, of course, that the current directory is in your `PATH`, which we will assume from now on).
To make `nu` part of your repertoire regardless of what directory you're in, move it to your private `bin` directory, and add `/usr/you/bin` to your search path:
```
$ pwd
/usr/you
$ mkdir bin
$ echo $PATH
:/usr/you/bin:/bin:/usr/bin
$ mv nu bin
$ ls nu
nu not found
$ nu
      4
$
```
Of course, your `PATH` should be set properly by your `.profile`, so you don't have to respect it every time you log in.

There are other simple commands that you might create this way to tailor your environment to your own taste.
Some that we have found convenient include
- `cs`
  - which echoes the proper sequence of mysterious characters to clear the screen on your terminal (24 newlines is a fairly general implementation)
- `what`
  - Which runs `who` and `ps -a` to tell who's logged on and what they are doing
- `where`
  - which prints out the identifying name of the UNIX system you're using - it's handy if you use several regularly. (Setting `PS1` serves a similar purpose.)

### 3.4 Command arguments and parameters

Although `nu` is adequate as it stands, most shell programs interpret arguments, so that, for example, filenames and options can be specified when the program is run.

Suppose we want to make a program called `cx` to change the mode of a file to executable, so
```
$ cx nu
```
is shorthand for
```
$ chmod +x nu
```
We already know almost enough to do this.
We need a file called `cx` whose contents are
```
chmod +x filename
```
The only thing new we need to know is how to tell `cx` what the name of the file is, since it will be different each time `cx` is run.

When the shell file executes a file of commands, each occurrence of `$1` is replaced by the first argument, each `$2` is replaced by the second argument, and so on through `$9`.
So if the file `cx` contains
```
chmod +x $1
```
when the command
```
$ cx nu
```
is run, the sub-shell replaces `$1` by its first argument, `nu`.

Let's look at the whole sequence of operations:
```
$ echo 'chmod +x $1' > cx           Create cx originally
$ sh cx cx                          Make cx itself executable
$ echo 'echo Hi, there!' > hello    Make a test program
$ hello                             Try it
hello: cannot execute
$ cx hello                          Make it executable
$ hello                             Try again
Hi, there!                          It works
$ mv cx /usr/you/bin                Install cx
$ rm hello                          Clean up
$
```
Notice that we said
```
$ sh cx cx
```
exactly as the shell would have automatically done if `cx` were already executable and we typed
```
$ cx cx
```

What if you want to handle more than one argument, for example to make a program like `xc` handle several files at once?
A crude first cut is to put nine arguments into the shell program, as in
```
chmod +x $1 $2 $3 $4 $5 $6 $7 $8 $9
```
(it only works up to `$9`, because the string `$10` is parsed as "first argument `$1` followed by a `0`"!)
If the user of this shell file provides fewer than nine arguments, the missing ones are null strings; the effect is that only the arguments that were actually provided are passed to `chmod` by the sub-shell.
So this implementation works, but it's obviously unclean, and it fails if more than nine arguments are provided.

Anticipating this problem, the shell provides a shorthand `$*` that means "all the arguments."
The proper way to define `cx`, then, is
```
chmod +x $*
```
which works regardless of how many arguments are provided.

With `$*` added to your repertoire, you can make some convenient shell files, such as `lc` or `m`:
```
$ cd /usr/you/bin
$ cat lc
# lc: count number of lines in files
wc -l $*
$ cat m
# m: a concise way to type mail
mail $*
$
```
Both can sensibly be used without arguments.
If there are no arguments, `$*` will be null, and no arguments at all will be passed to `wc` or `mail`.
With or without arguments, the command is invoked properly:
```
$ lc /usr/you/bin/*
      1 /usr/you/bin/cx
      2 /usr/you/bin/lc
      2 /usr/you/bin/m
      1 /usr/you/bin/nu
      2 /usr/you/bin/what
      1 /usr/you/bin/where
      9 total
$ ls /usr/you/bin | lc
      6
$
```

These commands and the others in this chapter are examples of *personal* programs, the sort of things you write for yourself and put in your `bin`, but are unlikely to make publicly available because they are too dependent on personal taste.
In Chapter 5 we will address the issues of writing shell programs suitable for public use.

The arguments to a shell file need not be filenames.
For example, consider searching a personal telephone directory.
If you have a file names `/usr/you/lib/phone-book` that contains lines like
```
dial-a-joke	212-976-3838
dial-a-prayer	212-246-4200
dial santa	212-976-3636
dow jones report	212-976-4141
```
then the `grep` command can be used to search it.
(Your own `lib` directory is a good place to store such personal data bases.)
Since `grep` doesn't care about the format of information, you can search for names, addresses, zip-codes, or anything else that you like.
Let's make a directory assistance program, which we'll call `411` in honor of the telephone directory assistance number where we live:
```
$ echo 'grep $* /usr/you/lib/phone-book' > 411
$ cx 411
$ 411 joke
dial-a-joke	212-976-3838
$ 411 dial
dial-a-joke	212-976-3838
dial-a-prayer	212-246-4200
dial santa	212-976-3636
$ 411 'dow jones'
grep: can't open jones
$                                 Something is wrong
```
The final example is included to show a potential problem: even though `dow jones` is presented to `411` as a single argument, it contains a space and is no longer in quotes, so the sub-shell interpreting the `411` command converts it into two arguments to `grep`: it's as if you had typed
```
$ grep dow jones /usr/you/lib/phone-book
```
and that's obviously wrong.

One remedy relies on the way the shell treats double quotes.
Although anything quoted with `'...'` us inviolate, the shell looks inside `"..."` for `$`'s `\\`'s, and `'...'`'s.
So if you revise `411` to look like
```
grep "$*" /usr/you/lib/phone-book
```
the `$*` will be replaced by the arguments, but it will be passed to `grep` as a single argument even if it contains spaces.
```
$ 411 dow jones
dow jones report	212-976-4141
$
```

By the way, you can make `grep` (and thus `411`) case-independent with the `-y` option:
```
$ grep -y pattern ...
```
With `-y`, lower case letters in `pattern` will also match upper case letters in the input.
(This option is in the 7th Edition `grep`, but is absent from some other systems.)

There are fine points about command arguments that we are skipping over until Chapter 5, but one is worth noting here.
The argument `$0` is the name of the program being executed - in `cx`, `$0` is `"cx"`.
A novel use of `$0` is in the implementation of the programs `2`, `3`, `4`, ..., which print their output in that many columns:
```
$ who | 2
drh			tty0		Sep 28 21:23			cvw			tty5		Sep 28 21:09
dmu			tty6		Sep 28 22:10			scj			tty7		Sep 28 22:11
you			tty9  	Sep 28 23:00			jib			ttyb		Sep 28 19:58
```

The implementations of `2`, `3`, ... are identical; in fact they are links to the same file:
```
$ ln 2 3; ln 2 4; ln 2 5; ln 2 6; 
$ ls -li [1-9]
16722 -rwxrwxrwx 5 you			51 Sep 28 23:21 2
16722 -rwxrwxrwx 5 you			51 Sep 28 23:21 3
16722 -rwxrwxrwx 5 you			51 Sep 28 23:21 4
16722 -rwxrwxrwx 5 you			51 Sep 28 23:21 5
16722 -rwxrwxrwx 5 you			51 Sep 28 23:e1 6
$ ls /usr/you/bin | 5
...
...
$ cat 5
# 2, 3, ...: print in n columns
pr -$0 -t -l1 $*
```
The `-t` option turns off the heading at the top of the page and the `-ln` option sets the page length to `n` lines.
The name of the program becomes the number-of-columns argument to `pr`, so the output is printed a row at a time in the number of columns specified by `$0`.

### 3.5 Program output as arguments

Let us turn now from command arguments within a shell file to the generation of arguments.
Certainly filename expansion from metacharacters like `*` is the most common way to generate arguments (other than by providing them explicitly), but another good way is by running a program.
The output of any program can be placed in a command line by enclosing the invocation in backquotes (\`...\`)
```
$ echo At the tone the time will be `date`.
At the tone the time will be Sun Jun 16 22:19:42 CDT 2019.
$
```
A small change illustrates that \`...\` is interpreted inside double quotes `"..."`:
```
$ echo "At the tone
> the time will be `date`."
At the tone
the time will be Mon Jun 17 09:36:43 CDT 2019.
$
```

As another example, suppose you want to send mail to a list of people whose login names are in the file `mailinglist`.
A clumsy way to handle this is to edit `mailinglist` into a suitable `mail` command and present it to she shell, but it's far easier to say
```
$ mail `cat mailinglist` < letter
```
This runs `cat` to produce the list of user names, and those become the arguments to `mail`. 
(When interpreting output in backquotes as arguments, the shell treats newlines as word separators, not command-line terminators; this subject is discussed fully in Chapter 5.)
Backquotes are easy enough to use that there's really no need for a separate mailing-list option to the `mail` command.

A slightly different approach is to convert the file `mailinglist` from just a list of names into a program that prints the list of names:
```
$ cat mailinglist
echo don whr ejs mb
$ cx mailinglist
$ mailinglist
don whr ejs mb
$
```

With the addition of one more program, it's even possible to modify the user list interactively.
The program is called `pick`:
```
$ pick arguments...
```
present the `arguments` one at a time and waits after each for a response.
The output of `pick` is those arguments selected by `y` (for "yes") responses; any other response causes the argument to be discarded.
For example,
```
$ pr `pick *.c` | lpr
```
presents each filename that ends in `.c`; those selected are printed with `pr` and `lpr`.
(`pick` is not part of the 7th Edition, but it's so easy and useful that we've included versions of it in Chapters 5 and 6.)

Suppose you have the second version of `mailinglist`.
Then
```
$ mail `pick \`mailinglist\`` < letter
don? y
whr?
ejs?
mb? y
$
```
sends the letter to `don` and `mb`.
Notice that there are nested backquotes; the backslashes prevent the interpretation of the inner \`...\` during the parsing of the outer one.

### 3.6 Shell variables

The shell has variables, like those in most programming languages, which in shell jargon are sometimes called *parameters*.
Strings such as `$1` are *positional parameters* - variables that hold the arguments to a shell file.
The digit indicates the position on the command line.
We have seen other shell variables: `PATH` is the list of directories to search for commands, `HOME` is your login directory, and so on.
Unlike variables in a regular language, the argument variables cannot be changed; although `PATH` is a variable whose value is `$PATH`, there is no variable `1` whose value is `$1`.
`$1` is nothing more than a compact notation for the first argument.

Leaving positional parameters aside, shell variables can be created, accessed, and modified.
For example,
```
$ PATH=:/bin/usr/bin
```
is an assignment that changes the search path.
There must be no spaces around the equals sign, and the assigned value must be a single word, which means it must be quoted if it contains shell metacharacters that should not be interpreted.
The value of a variable is extracted by preceding the name by a dollar sign:
```
$ PATH=$PATH:/usr/games
$ echo $PATH
:/usr/you/bin:/bin:/usr/bin:/usr/games
$ PATH=:/usr/you/bin:/bin:/usr/bin
$
```

Not all variables are special to the shell.
You can create new variables by assigning them to values; traditionally, variables with special meaning are spelled in upper case, so ordinary names are in lower case.
One of the common uses of variables is to remember long strings such as pathnames:
```
$ pwd
/usr/you/bin
$ dir=`pwd`              Remember where we are
$ cd /usr/mary/bin       Go somewhere else
$ ln $dir/cx .           Use the variable in a filename
$ ...                    Work for a while
$ cd $dir                Return
$ pwd
/usr/you/bin
$
```

The shell build-in command `set` displays the values of all your defined variables.
To see just one or two, `echo` is more appropriate.
```
$ set
HOME=/usr/you
IFS=

PATH=:usr/you/bin:/bin:/usr/bin
PS1=$
PS2=>
dir=/usr/you/bin
$ echo $dir
/usr/you/bin
$
```

The value of a variable is associated with the shell that creates it, and is not automatically passed to the shell's children.
```
$ x=Hello                Create x
$ sh                     New shell
$ echo $x
                         Newline only: x undefined in sub-shell
$ ctl-d                  leave this shell
$                        back in original shell
$ echo $x                
Hello                    x still defined
$
```
This means that a shell file cannot change the value of a variable, because the shell file is run by a sub-shell:
```
$ echo `x="Good Bye"     Make a two-line shell file...
> echo $x` > setx        ... to set and print x
$ cat setx
x="Good Bye"
echo $x
$ echo $x
Hello                    x is Hello in the original shell
sh setx
Good Bye                 x is Good Bye in the sub-shell...
$ echo $x
Hello                    ...but still Hello in this shell
$
```

There are times when using a shell file to change shell variables would be useful, however.
An obvious example is a file to add a new directory to your `PATH`.
The shell therefore provides a command `.` (dot) that executes the commands in a file in the current shell, rather than in a sub-shell.
This was originally invented so people could re-execute their `.profile` files without having to log in again, but it has other uses:
```
$ cat /usr/you/bin/games
PATH=$PATH:/usr/games    Append /usr/games/to PATH
$ echo $PATH
:/usr/you/bin:/bin:/usr/bin
$ . games
$ echo $PATH
:/usr/you/bin:/bin:/usr/bin
$
```
The file for the `.` command is searched for with the `PATH` mechanism, so it can be placed in your `bin` directory.

When a file is executing with `.`, it is only superficially like running a shell file.
The file is not "executed" in the usual sense of the word.
Instead, the commands in it are interpreted exactly as if you had typed them interactively - the standard input of the shell is temporarily redirected to come from the file.
Since the file is read but not executed, it need not have execute permissions.
Another difference is that the file does not receive command line arguments; instead `$1`, `$2`, and the rest are empty.
It would be nice if arguments were passed, but they are not.

The other way to see the value of a variable in a sub-shell is to assign to it explicitly on the command line *before* the command itself:
```
$ echo `echo $x` > echox
$ cx echox
echo $x
Hello                    As before
$ echox
                         x not set in sub-shell
$ x=Hi echox
Hi                       Value of x passed to sub-shell
$
```
(Originally, assignments anywhere in the command line were passed to the command, but this interfered with `dd`(1).)

The `.` mechanism should be used to change the value of a variable permanently, while in-line assignments should be used for temporary changes.
As an example, consider again searching `/usr/games` for commands, with the directory not in your `PATH`:
```
$ ls /usr/games | grep fort
fortune                            Fortune cookie command
$ fortune
fortune: not found
$ echo $PATH
:/usr/you/bin:/bin:/usr/bin
$ PATH=/usr/games fortune
Ring the bell; close the book; quench the candle.
$ echo $PATH
:/usr/you/bin:/bin:/usr/bin        PATH unchanged 
$ cat /usr/you/bin/games
PATH=$PATH:/usr/you/games          games command still there
$ . games
$ fortune
Premature optimization is the root of all evil - Knuth
$ echo $PATH
:/usr/you/bin:/bin:/usr/bin:/usr/games    PATH unchanged 
$
```

It's possible to exploit both these mechanisms in a single shell file.
A slightly different `games` command can be used a single time without changing `PATH`, or can set `PATH` permanently to include `/usr/games`:
```
$ cat /usr/you/bin/games
PATH=$PATH:/usr/games $*
$ cx /usr/you/bin/games
$ echo $PATH
:/usr/you/bin:/bin:/usr/bin
$ . games
$ echo $PATH
:/usr/you/bin:/bin:/usr/bin:/usr/games
$ fortune
He who hesitates is sometimes saved.
$
```
The first call to `games` ran the file in a sub-shell, where `PATH` was temporarily modified to include `/usr/games`.
The second example instead interpreted the file in the current shell, with `$*` the empty string, so there was no command on the line, and `PATH` was modified.
Using `games` in these two ways is tricky, but results in a facility that is convenient and natural to use.

When you want to make the value of a variable accessible in sub-shells, the shell's `export` command should be used.
(You might think about why there is no way to export the value of a variable from a sub-shell to its parent.)
Here is one of our earlier examples, this time with the variable `exported`:
```
$ x=Hello
$ export x
$ sh                     New shell
$ echo $x
Hello                    x known in sub-shell
$ x='Good Bye'           Change its value
$ echo $x
Good Bye
$ ctl-d                  Leave this shell
$                        Back in original shell
$ echo $x
Hello                    x still Hello
$
```
`export` has subtle semantics, but for day-to-day purposes at least, a rule of thumb suffices: don't export temporary variables set for short-term convenience, but always export variables you want set in all your shells and sub-shells (including, for example, shells started with `ed`'s `!` command).
Therefore, variables special to the shell, such as `PATH` and `HOME`, should always be exported.

### 3.7 More on I/O redirection

The standard error was invented so that error messages would always appear on the terminal:
```
$ diff file1 file12 > diff.out
diff: file12: no such file or directory
$
```
It's certainly desirable that error messages work this way - it would be most unfortunate if they disappeared into `diff.out`, leaving you with the impression that the erroneous `diff` command had worked properly.

Every program has three files established when it starts, numbered by small integers called *file descriptors* (which we will return to in Chapter 7).
The standard input, `0`, and the standard output, `1`, which we are already familiar with, are often redirected from and into files and pipes.
The last, numbered `2`, is the *standard error* output, and normally finds its way to your terminal.

Sometimes programs produce output on the standard error even when they work properly.
One common example is the program `time`, which runs a command and then reports on the standard error how much time it took.
```
$ time wc ch3.1
		931		4228		22691		ch3.1

real			1.0
user			0.4
sys				0.4
$ time wc ch3.1 > wc.out

real			2.0
user			0.4
sys				0.3
$ time wc ch3.1 > wc.out 2>time.out
$ cat time.out

real			1.0
user			0.4
sys				0.3
$
```
The notation `2>filename` (no spaces are allowed between the `2` and the `>`) directs the standard error output into the file; its syntactically graceless but it does the job.
(The times produced by `time` are not very accurate for such a short test as this one, but for a sequence of longer tests the numbers are useful and reasonably trustworthy, and you might well want to save them for further analysis; see, for example, Table 8.1)

It is also possible to merge the two output streams:
```
$ time wc ch3.1 > wc.out 2>&1
cat wc.out
		931		4228		22691		ch3.1

real			1.0
user			0.4
sys				0.3
$
```
The notation `2>&1` tells the shell to put the standard error on the same stream as the standard output.
There is not much mnemonic value to the ampersand; it's simply an idiom to be learned.
You can also use `1>&2` to add the standard output to the standard error:
```
$ echo ... 1>&2
```
prints on the standard error.
In shell files, it prevents messages from vanishing accidentally down a pipe or into a file.

The shell provides a mechanism so you can put the standard input for a command along with the command, rather than in a separate file, so the shell file can be completely self-contained.
Our directory information program `411` could be written
```
$ cat 411
grep "*." <<End
dial-a-joke	212-976-3838
dial-a-prayer	212-246-4200
dial santa	212-976-3636
dow jones report	212-976-4141
End
$
```
The shell jargon for this construction is a *here document*; it means that the input is right here instead of in a file somewhere.
The `<<` signals the construction; the word that follows (`End` in our example) is used to delimit the input, which is taken to be everything up to an occurrence of that word on a line by itself.
The shell substitutes for `$`, \`...\`, and `\\` in a here document, unless some part of the word is quoted with quotes or a backslash; in that case, the whole document is taken literally.

We'll return to here documents at the end of this chapter, with a much more interesting example.

Table 3.2 lists the various input-output redirections that the shell understands.

| notation   | description                                                                  |
|------------|------------------------------------------------------------------------------|
| `>file`    | direct standard output to `file`                                             |
| `>>file`   | append standard output to `file`                                             |
| `<file`    | take standard output from `file`                                             |
| `p1pipep2` | connect standard output of program `p1` to input of `p2`                     |
| `^`        | obsolete synonym for pipe                                                    |
| `n>file`   | direct output from file descriptor `n` to `file`                             |
| `n>>file`  | append output from file descriptor `n` to `file`                             |
| `n>&m`     | merge output from file descriptor `n` with file descriptor `m`               |
| `n<&m`     | merge input from file descriptor `n` with file descriptor `m`                |
| `<<s`      | here document: take standard input until next `s` at beginning of a new line |
| `<<\s`     | here document with no substitution                                           |
| `<<'s'`    | here document with no substitution                                           |


### 3.8 Looping in shell programs

The shell is actually a programming language: it has variables, loops, decision making, and so on.
We will discuss basic looping here, and talk more about control flow in Chapter 5

Looping over a set of filenames is very common, and the shell's `for` statement is the only control-flow statement that you might commonly type at the terminal rather than putting in a file for later execution.
The syntax is:
```
for var in list of words
do
			commands
done
```
For example, a `for` statement to echo filenames one per line is just
```
$ for i in *
> do
>     echo $i
> done
```
The `i` can be any shell variable, although `i` is traditional.
Note that the variable's value is accessed by `$i`, but that the `for` loop refers to the variable as `i`.
We used `*` to pick up all the files in the current directory, but any other list of arguments can be used.
Normally you want to do something more interesting than merely printing filenames.
One thing we do frequently is to compare a set of filenames with previous versions.
For example, to compare the old version of Chapter 2 (kept in directory `old`) with the current one:
```
$ ls ch2.*
ch2.1			ch2.2			ch2.3			ch2.4			ch2.5			ch2.6			ch2.7
$ for i in ch2.*
> do
>			echo $i;
>			diff -b old/$i $i
>			echo                         Add a blank line for readibility
> done | pr -h "diff `pwd`/old `pwd`" | lpr &
3712                               Process id
$
```
We piped the output into `pr` and `lpr` just to illustrate that it's possible: the standard output of the programs within a `for` goes to the standard output of the `for` itself.
We put a frequency heading on the output with the `-h` option of `pr`, using two embedded calls of `pwd`.
And we set the whole sequence running asynchronously (`&`) so we wouldn't have to wait for it; the `&` applies to the entire loop and pipeline.

We prefer to format a `for` statement as shown, but you can compress it somewhat.
The main limitations are that `do` and `done` are only recognized as keywords when they appear right after a newline or semicolon.
Depending on the size of the `for`, it's sometimes better to write it all on one line:
```
$ for i in list; do commands; done
```

You should use the `for` loop for multiple commands, or where the built-in argument processing in individual commands is not suitable.
But don't use it when the individual command will already loop over filenames:
```
# poor idea:
for i in $*
do
			chmod +x $i
done
```
is inferior to
```
chmod +x $*
```
because the `for` loop executes a separate `chmod` for each file, which is more expensive in computer resources.
(Be sure that you understand the difference between
```
for i in *
```
which loops over all filenames in the current directory, and
```
for i in $*
```
which loops over all arguments to the shell file.)

The argument list for a `for` mist often comes from pattern matching on filenames, but it can come from anything.
It could be
```
$ for i in `cat ...`
```
or the arguments could just be typed.
For example, earlier in this chapter we created a group of programs for multi-column printing, called `2`, `3`, and so on.
These are just links to a single file that can be made, once the file `2` has been written, by
```
$ for i in 2 3 4 5; do ln 2 $i; done
$
```

As a somewhat more interesting use of the `for`, we could use `pick` to select which files to compare with those in the backup directory:
```
$ for i in `pick ch2.*`
> do
> 			echo $i
> 			diff old/$i $i
> done | pr | lpr
ch2.1? y
ch2.2?
ch2.3?
ch2.4? y
ch2.5? y
ch2.6?
ch2.7?
$
```
It's obvious that this loop should be placed in a shell file to save typing next time: if you've done something twice, you're likely to do it again.

### 3.9 `bundle`: Putting it All Together

To give something of the flavor of how shell files develop, let's work through a larger example.
Pretend you have received mail from a friend on another machine, say `somewhere!bob`, who would like copies of the shell files in your `bin`.
The simplest way to send them is by return mail, so you could start by typing
```
$ cd /usr/you/bin
$ for i in `pick *`
> do
> 			echo ============ This is file $i ============
>				cat $i
> done | mail somewhere!bob
$
```
But look at it from `somewhere!bob`'s viewpoint: he's going to get a mail message with all the files clearly demarcated, but he'll need an editor to break them into their component files.
The flash of insight is that a properly constructed mail message could automatically unpack itself so the recipient needn't do any work.
This implies that it should be a shell file containing both the files and the instructions to unpack it.

A second insight is that the shell's here documents are a convenient way to combine a command invocation and the data for a command.
The rest of the job is just getting the quotes right.
Here's a working program, called `bundle`, that groups the files together into a self-explanatory shell file on it's standard output:
```
$ cat bundle
# bundle:	group files into distribution package

echo 'To unbundle, sh this file'
for i
do
			echo "echo $i 1>&2"
			echo "cat >$i <<'Endof $i'"
			cat $i
			echo "End of $i"
done
$
```
Quoting `"End of $i"` ensures that any shell metacharacters in the files will be ignored.

Naturally, you should try it out before inflicting it on `somewhere!bob`:
```
$ bundle cx lc >junk                        Make a trial bundle
$ cat junk
# To unbundle, sh this file
echo cx 1>&2
cat >cx <<'End of cx'
chmod +x $*
End of cx
echo lc 1>&2
cat >lc <<'End of lc'
# lc: count number of lines in files
wc -l $*
End of lc
$ mkdir test
$ cd test
$ sh ../junk                                Try it out
cx
lc
$ ls
cx
lc
$ cat cx
chmod +x $*
$ cat lc
# lc: count number of lines in files
wc -l $*                                    Looks good
$ cd ..
rm junk test/*; rmdir test                  Clean up
$ pwd
/usr/you/bin
$ bundle `pick *` | mail somewhere!bob      Sent the files
```

There's a problem if one of the files you're sending happens to contain a line of the form
```
End of filename
```
but it's a low probability event.
To make `bundle` utterly safe, we need a thing or two from later chapters, but it's eminently usable and convenient as it stands.

`bundle` illustrates much of the flexibility of the UNIX environment: it uses shell loops, I/O redirection, here documents and shell files, it interfaces directly to `mail`, and, perhaps most interesting, it is a program that creates a program.
It's one of the prettiest shell programs we know -  a few lines of code that do something simple, useful, and elegant.

### 3.10 Why a Programmable Shell?

The UNIX shell isn't typical of command interpreters: although it lets you run commands in the usual way, because it is a programming language, it can accomplish much more.
It's worth a brief look back at what we've seen, in part because there's a lot of material in this chapter but more because we promised to talk about "commonly used features" and then wrote about 30 pages of shell programming examples.
But when using the shell you write little one-line programs all the time: a pipeline is a program, as is our "Tea is ready" example.
The shell works like that: you program it constantly, but it's so easy and natural (once you're familiar with it) that you don't think of it as programming.

The shell does some things, like looping, I/O redirection with `<` and `>`, and filename expansion with `*`, so that no program need worry about them, and more importantly, so that the application of these facilities is uniform across all programs.
Other features, such as shell files and pipes, are really provided by the kernel, but the shell gives a natural syntax for creating them.
They go beyond convenience, to actually increasing the capabilities of the system.

Much of the power and convenience of the shell derives from the UNIX kernel underneath it; for example, although the shell sets up pipes, the kernel actually moves the data through them.
The way the system treats executable files makes it possible to write shell files so that they are run exactly like compiled programs.
The user needn't be aware that they are command files - they aren't invoked with a special command like `RUN`.
Also, the shell is a program itself, not part of the kernel, so it can be tuned, extended, and used like any other program.
This idea is not unique to the UNIX system, but it has been exploited better there than anywhere else.

In Chapter 5, we'll return to the subject of shell programming, but you should keep in mind that whatever you're doing with the shell, you're programming it - that's largely why it works so well.

