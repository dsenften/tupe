## Chapter 8: Program Development

The UNIX system was originally meant as a program development environment.
In this chapter we'll talk about some of the tools that are particularly suited for developing programs.
Our vehicle is a substantial program, an interpreter for a program language comparable in power to BASIC.
We chose to implement a language because it's representative of problems encountered in large programs.
Furthermore, many programs can profitably be viewed as languages that convert a systematic input into a sequence of actions and outputs, so we want to illustrate the language development tools.

In this chapter, we will cover specific lessons about
- `yacc`, a parser generator, a program that generates a parser from a grammatical description of a language.
- `make`, a program for specifying and controlling the processes by which a complicated program is compiled.
- `lex`, a program analogous to `yacc`, for making lexical analyzers.

We also want to convey some notions of how to go about such a project - the importance of starting with something small and letting it grow; language evolution; and the use of tools.

We will describe the implementation of the language in six stages, each of which would be useful even if the development went no further.
These stages closely parallel the way that we actually wrote the program.

1. A four function calculator, providing `+`, `-`, `*`, `/`, and parentheses, that operates on floating point numbers. One expression is typed on each line; its value is printed immediately.
2. Variables with names `a` through `z`. This version also has unary minus and some defenses against errors.
3. Arbitrarily-long variable names, built-in functions for `sin`, `exp`, etc., useful constants like `Ï€` (spelled `PI` because of typographic limitations), and an exponentiation operator.
4. A change in internals; code is generated for each statement and subsequently interpreted, rather than being evaluated on the fly. No new features are added, but it leads to version 5.
5. Control flow: `if-else` and `while`, statement grouping with `{` and `}`, and relational operators like `>`, `<=`, etc.
6. Recursive functions and procedures, with arguments. We also added statements for input and output of strings as well as numbers.

The resulting language is described in Chapter 9, where it serves as the main example in our presentation of the UNIX document preparation software.
Appendix 2 is the reference manual.

This is a very long chapter, because there's a lot of detail involved in getting a non-trivial program written correctly, let alone presented.
We are assuming that you understand C, and that you have a copy of the *UNIX Programmer's Manual*, Volume 2, close at hand, since we simply don't have space to explain every nuance.
Hang in, and be prepared to read the chapter a couple of times.
We have also included all of the code for the final version in Appendix 3, so you can see more easily how the pieces fit together.

By the way, we wasted a lot of time debating names for this language, but never came up with anything satisfactory.
We settled on `hoc`, which stands for "high-order calculator."
The versions are thus `hoc1`, `hoc2`, etc.

### 8.1 Stage 1: A four-function calculator

This section describes the implementation of `hoc1`, a program that provides about the same capabilities as a minimal pocket calculater, and is substantially less portable.
It has only four functions: `+`, `-`, `*`, and `/`, but it does have parentheses that can be nested arbitrarily deeply, which few pocket calculators provide.
If you type an expression followed by RETURN, the answer will be printed on the next line:
```
$ hoc1
4*3*2
      24
(1+2) * (3+4)
      21
1/2
      0.5
355/113
      3.1415929
-3-4
hoc1: syntax error near line 4
$
```

#### Grammars

Ever since Backnus-Naur Form was developed for Algol, languages have been described by formal grammars.
The grammar for `hoc1` is small and simple in its abstract representation:
```
list:   expr \n
        list expr \n
expr:   NUMBER
        expr + expr
        expr - expr
        expr * expr
        expr / expr
        ( expr )
```
In other words, a `list` is a sequence of expressions, each followed by a newline.
An expression is a number, or a pair of expressions joined by an operator, or a parenthesized expression.

This is not complete.
Among other things, it does not specify the normal precedence and associativity of the operators, nor does it attach a meaning to any construct.
And although `list` is defined in terms of `expr`, and `expr` is defined in terms of `NUMBER`, `NUMBER` itself is nowhere defined.
These details have to be filled in to go from a sketch of the language to a working program.

#### Overview of `yacc`

`yacc` is a *parser generator*, that is, a program for converting a grammatical specification language like the one above into a parser that will parse statements in the language.
`yacc` provides a way to associate meanings with the components of the grammar in such a way that as the parsing takes place, the meaning can be "evaluated" as well.
The stages of using `yacc` are the following.

First, a grammar is written, like the one above, but more precise.
This specifies the syntax of the language.
`yacc` can be used at this stage to warn of errors and ambiguities in the grammar.

Second, each rule or *production* of the grammar can be augmented with an *action* - a statement of what to do when an instance of that grammatical form is found in a program being parsed.
The "what to do" part is written in C, with conventions for connecting the grammar to the C code.
This defines the semantics of the language.

Third, a *lexical analyzer* is needed, which will read the input being parsed and break it up into meaningful chunks for the parser.
A `NUMBER` is an example of a lexical chunk that is several characters long; single-character operators like `+` and `*` are also chunks.
A lexical chunk is traditionally called a *token*.

Finally, a controlling routine is needed, to call the parser that `yacc` built.

`yacc` processes the grammar and the semantic actions into a parsing function, named `yyparse`, and writes it out as a file of C code.
If `yacc` finds no errors, the parser, the lexical analyzer, and the control routine can be compiled, perhaps linked with other C routines, and executed.
The operation of this program is to call repeatedly upon the lexical analyzer for tokens, recognize the grammatical (syntactic) structure in the input, and perform the semantic actions as each grammatical rule is recognized.
The entry to the lexical scanner must be named `yylex`, since that is the function that `yyparse` calls each time it wants another token.
(All names used by `yacc` start with `y`.)

To be somewhat more precise, the input to `yacc` takes this form:
```yacc
%{
C statements like #include, declarations, etc. This section is optional.
%}
yacc declarations: lexical tokens, grammar variables, precedence and associativity information
%%
grammar rules and actions
%%
more C statements (optional):
main() { ...; yyparse(); ... }
yylex() { ... }
...
```
This is processed by `yacc` and the result written into a file called `y.tab.c`, whose layout is like this:
```c
C statements from between %{ and %}, if any
C statements from after second %%, if any
main() { ...; yyparse(); ... }
yylex() { ... }
...
yyparse() { parser, which calls yylex() }
```

It is typical of the UNIX approach that `yacc` produces C instead of a complied object (`.o`) file.
This is the most flexible arrangement - the generated code is portable and amenable to other processing whenever someone has a good idea.

`yacc` itself is a powerful tool.
It takes some effort to learn, but the effort is repaid many times over.
`yacc`-generated parsers are small, efficient, and correct (though the semantic actions are your own responsibility); many nasty parsing problems are taken care of automatically.
Language-recognizing programs are easy to build, and (probably more important) can be modified repeatedly as the language definition evolves.

#### Stage 1 program

The source code for `hoc1` consists of a grammar with actions, a lexical routine `yylex`, and a `main`, all in one file `hoc.y`.
(`yacc` filenames traditionally end in `.y`, but this convention is not enforced by `yacc` itself, unlike `cc` and `.c`.)
The grammar part is the first half of `hoc.y`:
```yacc
%{
#define YYSTYPE double /* data type of yacc stack */
%}
%token NUMBER
%left  '+' '-'  /* left associative, same precedence */
%left  '*' '/'  /* left associative, higher precedence */
%%
list:     /* nothing */
        | list '\n'
        | list expr '\n'    { printf("\t%.8g\n", $2); }
        ;
expr:     NUMBER        { $$ = $1; }
        | expr '+' expr { $$ = $1 + $3; }
        | expr '-' expr { $$ = $1 - $3; }
        | expr '*' expr { $$ = $1 * $3; }
        | expr '/' expr { $$ = $1 / $3; }
        | '(' expr ')'  { $$ = $2; }
        ;
%%
        /* end of grammar */
...
```

There's a lot of new information packed into these few lines.
We are not going to explain all of it, and certainly not how the parser works - for that, you will have to read the `yacc` manual.

Alternate rules are separated by a `|`.
Any grammar rule can have an associated action, which will be performed when an instance of that rule is recognized in the input.
An action is a sequence of C statements enclosed in braces `{` and `}`.
Within an action, `$n` (that is, `$1`, `$2`, etc.) refers to the value returned by the `n`-th component of the rule, and `$$` is the value to be returned as the value of the whole rule.
So, for example, in the rule
```
expr:  NUMBER  { $$ = $1; }
```
`$1` is the value returned by recognizing `NUMBER`; that value is to be returned as the value of the `expr`.
The particular assignment `$$ = $1` can be omitted - `$$` is always set to `$1` unless you explicitly set it to something else.

At the next level, when the rule is
```
expr:  expr '+' expr  { $$ = $$1 + $$3; }
```
the value of the result `expr` is the sum of the values from the two component `expr`'s.
Notice that `'+'` is `$2`; every component is numbered.

At the level above this, an expression followed by a newline (`'\n'`) is recognized as a list and its value printed.
If the end of the input follows such a construction, the parsing process terminates cleanly.
A `list` can be an empty string; this is how blank input lines are handled.

`yacc` is free form; out format is the recommended standard.

In this implementation, the act of recognizing or parsing the input also causes immediate evaluation of the expression.
In more complicated situations (including `hoc4` and its successors), the parsing process generates code for later execution.

You may find it helpful to visualize parsing as drawing a *parse tree* like the one in Figure 8.1, and to imagine values being computed and propagated up the tree from the leaves towards the root.

```mermaid
graph TD
1a[List] ---2a[List]
2a---3a["(empty)"]
1a---2b[expr]
1a---2c[\n]
2b---3b[NUMBER]
3b---4a[2]
2b---3c[+]
2b---3d[expr]
3d---4b[NUMBER]
4b---5a[3]
3d---4c[*]
3d---4d[NUMBER]
4d---5b[4]
```
The values of incompletely-recognized rules are actually kept on a stack; this is how the values are passed from one rule to the next.
The data type of this stack is normally an `int`, but since we are processing floating point numbers, we have to override the default.
The definition
```c
# define YYSTYPE double
```
sets the stack type to `double`.

Syntactic classes that will be recognized by the lexical analyzer have to be declared unless they are single character literals like `'+'` and `'-'`.
The declaration `%token` declares one or more such objects.
Left or right associativity can be specified if appropriate by using `%left` or `%right` instead of `%token`.
(Left associativity means that `a-b-c` will be parsed as `(a-b)-c` instead of `a-(b-c)`.)
Precedence is determined by order of appearance: tokens in the same declaration are at the same level of precedence; tokens declared later are of higher precedence.
In this way the grammar proper is ambiguous (that is, there are multiple ways to parse some inputs), but the extra information in the extra information in the declarations resolves the ambiguity.

The rest of the code is the routines in the second half of the file `hoc.y`:
```c
#include <stdio.h>
#include <ctype.h>
char *progname;  // for error messages
int lineno = 1;

main(int argc, char *argv[]) {
    progname = argv[0];
    yyparse();
}
```
`main` calls `yyparse` to parse the input.
Looping from one expression to the next is done entirely within the grammar, by the sequence of productions for `list`.
It would have been equally acceptable to put a loop around the call to `yyparse` in `main` and have the action for `list` print the value and return immediately.

`yyparse` in turn calls `yylex` repeatedly for input tokens.
Our `yylex` is easy: it skips blanks and tabs, converts strings of digits into a numeric value, counts input lines for error reporting, and returns any other characters as itself.
Since the grammar expects to see only `+`, `-`, `*`, `/`, `(`, `)`, and `\n`, any other character will cause `yyparse` to report an error.
Returning a `0` signals "end of file" to `yyparse`.
```c
yylex() {
    int c;

    while ((c = getchar()) == ' ' || c == '\t')
        ;

    if (c == EOF)
        return 0;

    if (c == '.' || isdigit(c)) {
        ungetc(c, stdin);
        scanf("%lf", &yylval);
        return NUMBER;
    }

    if (c == '\n')
        lineno++;

    return c;
}
```
The variable `yylval` is used for communication between the parser and the lexical analyzer; it is defined by `yyparse`, and has the same type as the `yacc` stack.
`yylex` returns the *type* of a token as its function value, and sets `yylcal` to the *value* of the token (if there is one).
For instance, a floating point number has the type `NUMBER` and a value like 12.34.
For some tokens, especially single characters like `'+'` and `'\n'`, the grammar does not use the value, only the type.
In that case, `yylcal` need not be set.

The `yacc` declaration `%token NUMBER` is converted into a `#define` statement in the `yacc` output file `y.tab.c`, so `NUMBER` can be used as a constant anywhere in the C program.
`yacc` chooses values that won't collide with ASCII characters.

If there is a syntax error, `yyparse` calls `yyerror` with a string containing the cryptic message `"syntax error"`.
The `yacc` user is expected to provide a `yyerror`; ours just passes the string on to another function, `warning`, which prints somewhat more information.
Later versions of `hoc` will make direct use of `warning`.
```c
yyerror(char *s) {
    warning(s, (char *) 0);
}

warning(char *s, *t) {
    fprintf(stderr, "%s: %s", progname, s);

    if (t)
        fprintf(stderr, " %s", t);

    fprintf(stderr, " near line %d\n", lineno);
}
```
This marks the end of the routines in `hoc.y`.

Compilation of a `yacc` program is a two-step process:
```
$ yacc hoc.y
$ cc y.tab.c -o hoc1
$ hoc1
2/3
        0.66666667
-3-4
hoc1: syntax error near line 1
$
```

#### Making changes - unary minus

We claimed earlier that using `yacc` makes it easy to change a language.
As an illustration, let's add unary minus to `hoc1`, so that expressions like
```
-3-4
```
are evaluated, not rejected as syntax errors

Exactly two lines have been added to `hoc.y`.
A new token `UNARYMINUS` is added to the end of the precedence section, to make unary minus have highest precedence:
```
%left  '+' '-'  /* left associative, same precedence */
%left  '*' '/'  /* left associative, higher precedence */
%left  UNARYMINUS
```
The grammar is augmented with one more production for `expr`:
```
expr:     NUMBER        { $$ = $1; }
        | '-' expr %prec UNARYMINUS { $$ = -$2; }
```
The `%prec` says that a unary minus sign (that is, a minus sign before an expression) has the precedence of `UNARYMINUS` (high); the action is to change the sign.
A minus sign between two expressions takes the default precedence.

#### A digression on `make`
### 8.2 Stage 2: Variables and error recovery
### 8.3 Stage 3: Arbitrary variable names; built-in functions
#### Another digression on `make`
#### A digression on `lex`
### 8.4 Stage 4: Compilation into a machine
#### A third digression on `make`
### 8.5 Stage 5: Control flow and relational operators
### 8.6 Stage 6: Functions and procedures; input/output
### 8.7 Performance evaluation
### 8.8 A look back
